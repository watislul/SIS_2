"""
–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä —Å —Ç–æ—á–Ω—ã–º –ø–æ–∏—Å–∫–æ–º —Ä–µ–π—Ç–∏–Ω–≥–∞ –ø–æ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
"""
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import json
import re
from datetime import datetime

def scrape_one_manga():
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ —Å —Ç–æ—á–Ω—ã–º –ø–æ–∏—Å–∫–æ–º —Ä–µ–π—Ç–∏–Ω–≥–∞...")
    
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    
    driver = webdriver.Chrome(options=options)
    
    try:
        url = "https://remanga.org/manga/solo-leveling/main"
        driver.get(url)
        time.sleep(3)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å HTML –¥–ª—è –ø–æ–∏—Å–∫–∞
        html = driver.page_source
        
        # –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö
        data = {
            "title": clean_title(get_title(driver)),
            "description": get_description(driver),
            "year": get_year(html),
            "rating": get_rating(driver),
            "url": url,
            "scraped_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ: {data['title']}")
        return data
        
    finally:
        driver.quit()

def clean_title(title):
    """–û—á–∏—Å—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –æ—Ç '–ß–∏—Ç–∞—Ç—å ' –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"""
    if title.startswith("–ß–∏—Ç–∞—Ç—å "):
        title = title[7:]
    return title.strip()

def get_title(driver):
    """–ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫"""
    try:
        return driver.find_element(By.TAG_NAME, "h1").text.strip()
    except:
        return driver.title.split("‚Äî")[0].strip()

def get_description(driver):
    """–ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ - —Ç–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ –∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
    try:
        # –ü–ï–†–í–´–ô –°–ü–û–°–û–ë: –ò—â–µ–º –ø–æ —Ç–æ—á–Ω–æ–º—É data-–∞—Ç—Ä–∏–±—É—Ç—É –∏–∑ HTML
        try:
            desc_elements = driver.find_elements(By.CSS_SELECTOR, '[data-sentry-component="Description"]')
            for elem in desc_elements:
                # –í–Ω—É—Ç—Ä–∏ –∏—â–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                paragraphs = elem.find_elements(By.TAG_NAME, "p")
                for p in paragraphs:
                    text = p.text.strip()
                    if text and len(text) > 50:
                        return text[:500]
        except:
            pass
        
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è: {e}")
        return ""

from bs4 import BeautifulSoup

def get_year(html):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–æ–¥ –∏–∑ HTML —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º BeautifulSoup –∏ —Ç–æ—á–Ω—ã—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
    soup = BeautifulSoup(html, 'html.parser')
    
    # –°–ø–æ—Å–æ–± 1: –ò—â–µ–º —Å—Å—ã–ª–∫—É —Å issue_year –≤ href (—Ç–æ—á–Ω–µ–µ)
    year_link = soup.find('a', href=lambda x: x and 'issue_year' in str(x))
    if year_link:
        year_text = year_link.get_text(strip=True)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∏–º–µ–Ω–Ω–æ –≥–æ–¥ (4 —Ü–∏—Ñ—Ä—ã)
        if year_text.isdigit() and len(year_text) == 4:
            return year_text
    
    
    
    return ""

def get_rating(driver):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑—É—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä"""
    try:
        stat_heading = driver.find_element(
            By.XPATH, 
            "//h3[contains(text(), '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞')]"
        )
        
        stat_container = stat_heading.find_element(By.XPATH, "../..")
        
        rating_elements = stat_container.find_elements(
            By.XPATH, 
            ".//*[contains(text(), '–†–µ–π—Ç–∏–Ω–≥ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è:')]"
        )
            
        for elem in rating_elements:
            text = elem.text.strip()
        
            match = re.search(r'(\d+\.\d+)', text)
            if match:
                rating = float(match.group(1))
                if 0.0 <= rating <= 10.0:
                    return match.group(1)
                    
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞: {str(e)[:100]}")
        return "0.0"

if __name__ == "__main__":
    result = scrape_one_manga()
    
    if result:
        with open("data/single_manga.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {result['title']}")
        print(f"  –û–ø–∏—Å–∞–Ω–∏–µ: {result['description'][:80]}...")
        print(f"  –ì–æ–¥: {result['year']}")
        print(f"  –†–µ–π—Ç–∏–Ω–≥: {result['rating']}")
        print(f"üìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/single_manga.json")